{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccf43bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 1. Library Imports and Initial Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import h3\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import abm_utils.abm as abm \n",
    "import abm_utils.repositioning as repositioning\n",
    "import abm_utils.split as split\n",
    "import joblib\n",
    "from q_utils.Q_agent import QLearningAgent\n",
    "from q_utils.RL_agent_v2 import EnhancedStateHandler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee01a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nHere we have a problem copying the value from one workspace to another. Renaming the file is not working at all.\\nThus for testing, a new q-table needs to be generated in Ql_train.ipynb\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialise State Handler\n",
    "state_handler = EnhancedStateHandler(n_distance_bins=10, n_courier_bins=10) \n",
    "\n",
    "# Create agent instance\n",
    "decision_agent = QLearningAgent(epsilon=0.0) # Epsilon = 0, because we want to use the Q-table only\n",
    "\n",
    "\"\"\"\n",
    "Here we have a problem copying the value from one workspace to another. Renaming the file is not working at all.\n",
    "Thus for testing, a new q-table needs to be generated in Ql_train.ipynb\n",
    "\"\"\"\n",
    "# Load q-table\n",
    "trained_q_table = joblib.load('Data/q_learning_agent_01_500.joblib')\n",
    "decision_agent.q_table = trained_q_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52f208d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_data_filtered = pd.read_csv(\"Data/TestData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81aab7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecastData = pd.read_parquet(\"Data/predicted_values_2022-10-24_14-17.parquet\") #Predicted values for our timeframe between 14-17 with h3 indices\n",
    "\n",
    "\"\"\"\n",
    "First we need to create a dictionary with all predicted values in hexagons res = 8, which our abm can use for repositioning\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "wide_df = forecastData.pivot(\n",
    "    index='time_bin',\n",
    "    columns='hex_id', \n",
    "    values='predicted_order_count'\n",
    ")\n",
    "\n",
    "wide_df.index = pd.to_datetime(wide_df.index)\n",
    "wide_df = wide_df.fillna(0)\n",
    "predictions_dict = wide_df.to_dict(orient='index')\n",
    "first_key = list(predictions_dict.keys())[0]\n",
    "\n",
    "pre_binned_demand = predictions_dict #pre_binned_demand is our 15 minutes bin per hexagon dictionary with which we will test our strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858d1a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_abm(timestart, steps, data, couriers, metrics, delivered_order_ids, order_queue, strategy, constants, rejection_model, assignment_log, decision_agent, state_handler):\n",
    "    \"\"\"\n",
    "    Our abm dispatcher which controls all simulation functions.\n",
    "    Args:   - constants will be defined in main simulation setup and is a tuple of numbers\n",
    "            - data is our dataframe for the three hours\n",
    "            - couriers are all couriers\n",
    "            - strategy is the strategy used\n",
    "            - metrics is a tuple of values to calculate simulation metrics (now with 6 values)\n",
    "            - rejection model is the imported logistic regression probabilistic model\n",
    "            - delivered_order_ids are the orders delivered so far and at what timestep\n",
    "            - order_queue is the set of orders, which are in the queue \n",
    "    \"\"\"\n",
    "    # Moving the couriers\n",
    "    couriers, metrics, delivered_order_ids = abm.move_couriers_new(\n",
    "        couriers, timestart, metrics, delivered_order_ids,\n",
    "        constants['SPEED_HEX_PER_STEP'], constants['steps']\n",
    "    )\n",
    "    if len(order_queue) > 50:\n",
    "        constants[\"MAX_ACCEPTABLE_DELAY_SECONDS\"] = 15 * 60\n",
    "    elif len(order_queue) > 20:\n",
    "        constants[\"MAX_ACCEPTABLE_DELAY_SECONDS\"]  = 10 * 60\n",
    "    else:\n",
    "        constants[\"MAX_ACCEPTABLE_DELAY_SECONDS\"]  = 5 * 60\n",
    "    # Different strategies need different functions\n",
    "    repositioning_enabled_strategies = ['Repositioning', 'Combined_Split']\n",
    "    splitting_enabled_strategies = ['Split', 'Combined_Split']\n",
    "    if strategy in repositioning_enabled_strategies and (timestart - constants['initial_timestart']) % constants['repositioning_interval'] == 0:\n",
    "        current_bin_key = pd.to_datetime(timestart, unit='s').floor('15min') + pd.Timedelta(hours=8)\n",
    "        dynamic_demand = constants['pre_binned_demand'].get(current_bin_key, {})\n",
    "        if dynamic_demand:\n",
    "            repositioning.run_repositioning_strategy(\n",
    "                couriers, dynamic_demand, timestart, order_queue,\n",
    "                constants['SPEED_HEX_PER_STEP'], constants['steps'],\n",
    "                constants['MACRO_RESOLUTION'], constants['WORK_RESOLUTION']\n",
    "            )\n",
    "\n",
    "    # prepare the orders for the step\n",
    "    new_orders_this_step = [order for _, order in data[\n",
    "        (data['platform_order_time'] >= timestart) & \n",
    "        (data['platform_order_time'] < timestart + steps)\n",
    "    ].iterrows()]\n",
    "    for order in new_orders_this_step:\n",
    "        order['assignment_status'] = 'pending_full'\n",
    "\n",
    "    all_pending_orders = order_queue + [(order, 0) for order in new_orders_this_step]\n",
    "    next_order_queue = []\n",
    "    processed_order_ids_this_step = set()\n",
    "\n",
    "    # process all orders\n",
    "    for order, attempts in all_pending_orders:\n",
    "        if order['order_id'] in processed_order_ids_this_step:\n",
    "            continue\n",
    "\n",
    "        was_processed = False\n",
    "        if attempts > constants['MAX_QUEUE_ATTEMPTS']:\n",
    "            was_processed, metrics, assignment_log = abm.handle_standard_assignment(order, attempts, couriers, timestart, constants, rejection_model, processed_order_ids_this_step, metrics, assignment_log)\n",
    "        #Only for splitting the agent decides\n",
    "        elif strategy in splitting_enabled_strategies:\n",
    "            \n",
    "            if order['assignment_status'] == 'pending_part2':\n",
    "                action = 0 # standard because it is in queue for a long time\n",
    "            else:\n",
    "                # Get the states and discretize the state\n",
    "                \n",
    "                state_features = state_handler.get_state_features(order, couriers)\n",
    "                current_state = state_handler.discretize_state(state_features)\n",
    "\n",
    "                \n",
    "                # get the action split or direct\n",
    "                action = decision_agent.get_action(current_state)\n",
    "\n",
    "            # execute action\n",
    "            if action == 0: #decision direct\n",
    "                was_processed, metrics, assignment_log = abm.handle_standard_assignment(order, attempts, couriers, timestart, constants, rejection_model, processed_order_ids_this_step, metrics, assignment_log)\n",
    "            \n",
    "            else: #decision split\n",
    "                idle_couriers = [c for c in couriers if c.state == 'IDLE' and order['order_id'] not in c.rejected_orders]\n",
    "                c1, c2, r1, r2 = split.process_split_delivery(order, idle_couriers, timestart, constants)\n",
    "                \n",
    "                if c1 and c2:\n",
    "                    was_processed, metrics = split.execute_split_assignment(\n",
    "                        order, c1, c2, r1, r2, timestart, constants, \n",
    "                        rejection_model, processed_order_ids_this_step, next_order_queue, metrics\n",
    "                    )\n",
    "        else: \n",
    "            was_processed, metrics, assignment_log = abm.handle_standard_assignment(order, attempts, couriers, timestart, constants, rejection_model, processed_order_ids_this_step, metrics, assignment_log)\n",
    "\n",
    "        if not was_processed: \n",
    "            next_order_queue.append((order, attempts + 1))\n",
    "\n",
    "    return couriers, data, metrics, delivered_order_ids, next_order_queue, assignment_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed571f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_effectiveness(results, total_active_couriers):\n",
    "    \"\"\"\n",
    "    Prints a summary of simulation results\n",
    "    Arg. results: A dictionary containing the simulation outcomes. Format: {(scale, strategy): (total_time, metrics, total_distance)}\n",
    "    \"\"\"\n",
    "    print(\"=\"*40 + \"Simulation results\" + \"=\"*40)\n",
    "\n",
    "    #iterate through each strategy and scale to print results for all\n",
    "    for params, res in results.items():\n",
    "        scale, strategy = params\n",
    "        total_time, metrics, total_distance = res\n",
    "        \n",
    "        # Unpack the new, extended metrics tuple\n",
    "        delay_inc, _, success, success_delay, stacked_count, rejected_count = metrics\n",
    "        \n",
    "        total_delivered = success + success_delay\n",
    "        if total_delivered == 0: continue\n",
    "        avg_delay = delay_inc / success_delay if success_delay > 0 else 0\n",
    "        \n",
    "        print(f\"Scenario: '{strategy}' @ {int(scale*100)}% Flotte ({int(total_active_couriers * scale)} Fahrer)\")\n",
    "        print(f\"Total Time to clear all orders: {total_time/3600:.2f} Stunden ({total_time/60:.0f} Minuten)\")\n",
    "        print(f\"On-time or Early Deliveries: {success}\")\n",
    "        print(f\"Late Deliveries: {success_delay}\")\n",
    "        print(f\"Avg. Delay (for late deliveries): {avg_delay/60:.1f} Minuten\")\n",
    "        print(f\"Total Distance Traveled (Hexagons): {total_distance} Zellen\")\n",
    "        print(f\"Total Stacked Assignments: {stacked_count}\")\n",
    "        print(f\"Total Rejected Offers: {rejected_count}\")\n",
    "        \n",
    "        print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cde44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation initialisiert. Metriken werden für 5240 'tracked' Aufträge gesammelt (nach t=30min).\n",
      "Starting Simulation:'Split' with 629 couriers (50%)...\n",
      "  > Time: 10 min | Delivered: 3/6420 | Queue: 10\n",
      "  > Time: 20 min | Delivered: 38/6420 | Queue: 18\n",
      "  > Time: 30 min | Delivered: 139/6420 | Queue: 16\n"
     ]
    }
   ],
   "source": [
    "constants = {\n",
    "    'initial_timestart': 1666591200, #2022-10-24 @14:00\n",
    "    'SPEED_HEX_PER_STEP': 8, #count of hexgagon jump per step in workresolution\n",
    "    'simulation_duration_hours': 3, #we simulate 14:00-17:00 e.g.\n",
    "    'steps': 30, #duration of a single simulation timestep in seconds\n",
    "    'repositioning_interval': 15 * 60, #the interval in seconds at which the repositioning strategy is triggered\n",
    "    'MAX_ACCEPTABLE_DELAY_SECONDS': 5 * 60, #for assignments, to wait for better courier\n",
    "    'MAX_QUEUE_ATTEMPTS': 20, #If in queue for 10 minutes -> best free courier is chosen \n",
    "    'pre_binned_demand': pre_binned_demand, # Our prediction for the three hours\n",
    "    'MACRO_RESOLUTION': 8, #Hexagon resolution demand prediction and zones\n",
    "    'WORK_RESOLUTION': 13 # Actors position and movement \n",
    "}\n",
    "final_courier_states = {} #for evaluation\n",
    "results = {} #for evaluation\n",
    "\n",
    "rejection_model = joblib.load('Data/rejection_model.joblib')\n",
    "\n",
    "warmup_duration_seconds = 30 * 60  # 30 Minuten\n",
    "\n",
    "# Berechnen Sie den Startzeitpunkt für die Metrikerfassung\n",
    "metrics_start_time = constants['initial_timestart'] + warmup_duration_seconds\n",
    "\n",
    "# Fügen Sie eine neue Spalte 'phase' hinzu, die die Aufträge kategorisiert\n",
    "sim_data_filtered['phase'] = np.where(\n",
    "    sim_data_filtered['platform_order_time'] < metrics_start_time, \n",
    "    'warmup', \n",
    "    'tracked'\n",
    ")\n",
    "\n",
    "# Informieren Sie den Benutzer über die Aufteilung\n",
    "tracked_orders_count = (sim_data_filtered['phase'] == 'tracked').sum()\n",
    "print(f\"Simulation initialisiert. Metriken werden für {tracked_orders_count} 'tracked' Aufträge gesammelt (nach t=30min).\")\n",
    "\n",
    "\n",
    "#determine the total number of couriers who were active in time window\n",
    "total_active_couriers = sim_data_filtered['courier_id'].unique().shape[0] \n",
    "total_active_couriers = total_active_couriers*0.8\n",
    "\n",
    "#define the scenarios to run\n",
    "strategies = ['Split', 'Combined_Split']\n",
    "repositioning_enabled_strategies = ['Repositioning', 'Combined_Split']\n",
    "courier_scales = [0.5]\n",
    "assignment_log_dict = {}\n",
    "\n",
    "#Loop through each fleet scale\n",
    "for scale in courier_scales:\n",
    "    for strategy in strategies: #loop through each strategy\n",
    "        \n",
    "        #reset the simulation states\n",
    "        start_time_real = time.time()\n",
    "        timestart = constants['initial_timestart'] \n",
    "        sim_data = sim_data_filtered.copy()\n",
    "        initial_order_ids = set(sim_data['order_id'])\n",
    "        num_initial_orders = len(initial_order_ids)\n",
    "        delivered_order_ids = set()\n",
    "        # metrics = (delay_inc, 0, success, success_delay, stacked_orders, rejected_orders)\n",
    "        metrics = (0, 0, 0, 0, 0, 0)\n",
    "        order_queue = []\n",
    "        assignment_log = []\n",
    "        \n",
    "        #initiate couriers at their position based on scale\n",
    "        couriers = abm.initiate_couriers(int(total_active_couriers * scale), sim_data_filtered)      \n",
    "       \n",
    "        \n",
    "        print(f\"Starting Simulation:'{strategy}' with {len(couriers)} couriers ({int(scale*100)}%)...\")\n",
    "\n",
    "        if strategy in repositioning_enabled_strategies:\n",
    "            #As we think that the fleet would not start at point zero\n",
    "            print(f\"Running warm up phase for fleet deployment\")\n",
    "            warmup_seconds = 15 * 60 \n",
    "            warmup_start_time = constants['initial_timestart']  - warmup_seconds\n",
    "            \n",
    "            for t in range(warmup_start_time, constants['initial_timestart'] , constants['steps'] ):\n",
    "                # Move couriers in repositioning task\n",
    "                couriers, _, delivered_order_ids = abm.move_couriers_new(couriers, t, (0, 0, 0, 0, 0, 0), delivered_order_ids, constants['SPEED_HEX_PER_STEP'], constants['steps'])\n",
    "\n",
    "                 # Use the pre-binned forecast for the first time-slot as the warm-up target.\n",
    "                first_bin_key = pd.to_datetime(constants['initial_timestart'] , unit='s').floor('15min') + pd.Timedelta(hours=8)\n",
    "                dynamic_demand = pre_binned_demand.get(first_bin_key, {})\n",
    "\n",
    "                # assign reposition tasks\n",
    "                if dynamic_demand:\n",
    "                    repositioning.run_repositioning_strategy(couriers, dynamic_demand, t, [], \n",
    "                        constants['SPEED_HEX_PER_STEP'], constants['steps'], \n",
    "                        constants['MACRO_RESOLUTION'], constants['WORK_RESOLUTION']\n",
    "                    )\n",
    "\n",
    "        # Main Simulation Loop Begins here\n",
    "        while len(delivered_order_ids) < num_initial_orders:\n",
    "            # Function call of abm\n",
    "            couriers, sim_data, metrics, delivered_order_ids, order_queue, assignment_log = run_abm(\n",
    "                timestart, constants['steps'] , sim_data, couriers, metrics, delivered_order_ids, order_queue,\n",
    "                strategy, constants, rejection_model , assignment_log,decision_agent=decision_agent,state_handler=state_handler\n",
    "            )\n",
    "            timestart += constants['steps']  #add steps\n",
    "\n",
    "            #Log every 10 minutes\n",
    "            if (timestart - constants['initial_timestart'] ) % 600 == 0 and timestart > constants['initial_timestart'] :\n",
    "                print(f\"  > Time: {(timestart - constants['initial_timestart'] )/60:.0f} min | Delivered: {len(delivered_order_ids)}/{num_initial_orders} | Queue: {len(order_queue)}\")\n",
    "            \n",
    "        # store metrics\n",
    "        total_simulation_time = timestart - constants['initial_timestart'] \n",
    "        end_time_real = time.time()\n",
    "        assignment_log_dict[(scale, strategy)] = assignment_log\n",
    "        \n",
    "        final_courier_states[(scale, strategy)] = couriers\n",
    "\n",
    "        total_distance = abm.calculate_total_distance_in_hexes(couriers)        \n",
    "        results[(scale, strategy)] = (total_simulation_time, metrics, total_distance)\n",
    "        total_distance = abm.calculate_total_distance_in_hexes(couriers)\n",
    "\n",
    "        \n",
    "        print(f\"Simulation (Skala {int(scale*100)}%) finished in {end_time_real - start_time_real:.2f} real seconds.\")\n",
    "        print(f\"All {num_initial_orders} orders delivered. Total simulation time: {total_simulation_time/60:.0f} minutes.\")\n",
    "\n",
    "#final evaluation\n",
    "evaluate_effectiveness(results, total_active_couriers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
