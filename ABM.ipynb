{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf43bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 1. Library Imports and Initial Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import jenkspy\n",
    "\n",
    "import abm_utils.hindsight_batching as hb\n",
    "import abm_utils.abm as abm \n",
    "import abm_utils.repositioning as repositioning\n",
    "import abm_utils.split as split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d11e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_data_filtered = pd.read_csv(\"Data/TestData.csv\") #the already prepared and filtered Test data set\n",
    "rejection_model = joblib.load('Data/rejection_model.joblib') #Trained model with rejection probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6b5fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_data_filtered['sqrt_hex_distance'] = np.sqrt(sim_data_filtered['hex_distance']) #The already calculated hex distance is manipulated with a square root to make the values more compact\n",
    "scaler = MinMaxScaler()\n",
    "sim_data_filtered['normalized_distance'] = scaler.fit_transform(sim_data_filtered[['sqrt_hex_distance']]) #Using a scaler for normalisation of the hex distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916a0356",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the normalized distances are classified with jenks natural break optimization in 10 bins\n",
    "data_series = sim_data_filtered['normalized_distance'] \n",
    "breaks = jenkspy.jenks_breaks(data_series, n_classes=10)\n",
    "jenks_binned = pd.cut(data_series, bins=breaks, include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81aab7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecastData = pd.read_parquet(\"Data/predicted_values_2022-10-24_14-17.parquet\") #Predicted values for our timeframe between 14-17 with h3 indices\n",
    "\"\"\"\n",
    "First we need to create a dictionary with all predicted values in hexagons res = 8, which our abm can use for repositioning\n",
    "\"\"\"\n",
    "wide_df = forecastData.pivot(\n",
    "    index='time_bin',\n",
    "    columns='hex_id', \n",
    "    values='predicted_order_count'\n",
    ")\n",
    "wide_df.index = pd.to_datetime(wide_df.index)\n",
    "wide_df = wide_df.fillna(0)\n",
    "predictions_dict = wide_df.to_dict(orient='index')\n",
    "first_key = list(predictions_dict.keys())[0]\n",
    "\n",
    "pre_binned_demand = predictions_dict #pre_binned_demand is our 15 minutes bin per hexagon dictionary with which we will test our strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858d1a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_abm(timestart, steps, data, couriers, metrics, delivered_order_ids, \n",
    "            order_queue, strategy, constants, rejection_model,assignment_log, hindsight_cache):\n",
    "    \"\"\"\n",
    "    Our abm dispatcher which controls all simulation functions.\n",
    "    Args:   - constants will be defined in main simulation setup and is a tuple of numbers\n",
    "            - data is our dataframe for the three hours\n",
    "            - couriers are all couriers\n",
    "            - strategy is the strategy used\n",
    "            - metrics is a tuple of values to calculate simulation metrics (now with 6 values)\n",
    "            - rejection model is the imported logistic regression probabilistic model\n",
    "            - delivered_order_ids are the orders delivered so far and at what timestep\n",
    "            - order_queue is the set of orders, which are in the queue \n",
    "            - hindsight_cache is the cache for plotting scenarios\n",
    "    \"\"\"\n",
    "    #Different strategies are allowed to use different utils\n",
    "    repositioning_enabled_strategies = ['Repositioning', 'Combined_Split','Combined_SPAB']\n",
    "    splitting_enabled_strategies = ['Split', 'Combined_Split']\n",
    "    hindsight_enabled_strategies = ['Combined_SPAB','SPAB'] \n",
    "\n",
    "    #At each timestep each courier with a task is moved\n",
    "    couriers, metrics, delivered_order_ids = abm.move_couriers_new(\n",
    "        couriers, timestart, metrics, delivered_order_ids,\n",
    "        constants['SPEED_HEX_PER_STEP'], constants['steps']\n",
    "    )\n",
    "    #We formulate thresholds based on the queue to reduce repositioning during system stress\n",
    "    if len(order_queue) > 50:\n",
    "        constants[\"MAX_ACCEPTABLE_DELAY_SECONDS\"] = 15 * 60\n",
    "    elif len(order_queue) > 20:\n",
    "        constants[\"MAX_ACCEPTABLE_DELAY_SECONDS\"]  = 10 * 60\n",
    "    else:\n",
    "        constants[\"MAX_ACCEPTABLE_DELAY_SECONDS\"]  = 5 * 60\n",
    "\n",
    "    #If we want to reposition, we start repositioning\n",
    "    if strategy in repositioning_enabled_strategies and (timestart - constants['initial_timestart']) % constants['repositioning_interval'] == 0:\n",
    "        current_bin_key = pd.to_datetime(timestart, unit='s').floor('15min') + pd.Timedelta(hours=8)\n",
    "        dynamic_demand = constants['pre_binned_demand'].get(current_bin_key, {})\n",
    "        if dynamic_demand:\n",
    "            repositioning.run_repositioning_strategy(\n",
    "                couriers, dynamic_demand, timestart, order_queue,\n",
    "                constants['SPEED_HEX_PER_STEP'], constants['steps'],\n",
    "                constants['MACRO_RESOLUTION'], constants['WORK_RESOLUTION']\n",
    "            )\n",
    "    processed_order_ids_this_step = set()\n",
    "    used_courier_ids_this_step = set()\n",
    "\n",
    "    # prepare the still existing orders for the step\n",
    "    new_orders_this_step = [order for _, order in data[\n",
    "        (data['platform_order_time'] >= timestart) & \n",
    "        (data['platform_order_time'] < timestart + steps)\n",
    "    ].iterrows()]\n",
    "    for order in new_orders_this_step:\n",
    "        order['assignment_status'] = 'pending_full'\n",
    "\n",
    "    #If we want to use the hindsight strategy\n",
    "    if strategy in hindsight_enabled_strategies:\n",
    "        couriers, order_queue, new_orders_this_step, hindsight_cache, used_courier_ids_this_step, processed_order_ids_this_step = hb.handle_hindsight_analysis(\n",
    "            timestart, order_queue, new_orders_this_step, couriers, constants, hindsight_cache\n",
    "        )   \n",
    "    \n",
    "    #all new orders combined with the orders from the queue\n",
    "    all_pending_orders = order_queue + [(order, 0) for order in new_orders_this_step]\n",
    "\n",
    "    #Important, that couriers with a bringer task are not allowed for two assignments in one step\n",
    "    safe_couriers_for_standard_assignment = [c for c in couriers if c.id not in used_courier_ids_this_step]\n",
    "\n",
    "    next_order_queue = [] #an empty set for new orders\n",
    "\n",
    "    # process all orders\n",
    "    for order, attempts in all_pending_orders:\n",
    "        if order['order_id'] in processed_order_ids_this_step:\n",
    "            continue\n",
    "\n",
    "        was_processed = False\n",
    "        if attempts > constants['MAX_QUEUE_ATTEMPTS']:\n",
    "            was_processed, metrics, assignment_log = abm.handle_standard_assignment(order, attempts, safe_couriers_for_standard_assignment, \n",
    "                                                                                    timestart, constants, rejection_model, \n",
    "                                                                                    processed_order_ids_this_step, metrics, assignment_log)\n",
    "        elif strategy in splitting_enabled_strategies:\n",
    "            # Check the distance bin directly from the “order” object.\n",
    "            # Orders whose bin number is less than the threshold are treated as standard.\n",
    "            if order['distance_bin'] < constants['SPLIT_BIN_THRESHOLD'] or order['assignment_status'] == 'pending_part2':\n",
    "                was_processed, metrics, assignment_log = abm.handle_standard_assignment(order, attempts, safe_couriers_for_standard_assignment, \n",
    "                                                                                        timestart, constants, rejection_model, \n",
    "                                                                                        processed_order_ids_this_step, metrics, assignment_log)\n",
    "            else:\n",
    "                # The split logic is only called for orders whose bin is >= the threshold value.\n",
    "                idle_couriers = [c for c in couriers if c.state == 'IDLE' and order['order_id'] not in c.rejected_orders]\n",
    "                c1, c2, r1, r2 = split.process_split_delivery(order, idle_couriers, timestart, constants)\n",
    "                \n",
    "                #If there is a split option with couriers, the assignment is executed\n",
    "                if c1 and c2:\n",
    "                    was_processed, metrics = split.execute_split_assignment(\n",
    "                        order, c1, c2, r1, r2, timestart, constants, \n",
    "                        rejection_model, processed_order_ids_this_step, next_order_queue, metrics\n",
    "                    )\n",
    "        else: #If we are not using the split assignment\n",
    "            was_processed, metrics, assignment_log = abm.handle_standard_assignment(order, attempts, safe_couriers_for_standard_assignment,\n",
    "                                                                                     timestart, constants, rejection_model,\n",
    "                                                                                       processed_order_ids_this_step, metrics, assignment_log)\n",
    "\n",
    "        if not was_processed: #If an order was not assigned to a courier, the number of attempts is increased and added to the queue\n",
    "            next_order_queue.append((order, attempts + 1))\n",
    "\n",
    "    return couriers, data, metrics, delivered_order_ids, next_order_queue, assignment_log, hindsight_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed571f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_effectiveness(results, total_active_couriers):\n",
    "\n",
    "    \"\"\"\n",
    "    Prints a summary of simulation results\n",
    "    Arg. - results: A dictionary containing the simulation outcomes. Format: {(scale, strategy): (total_time, metrics, total_distance)}\n",
    "         - Number of active couriers\n",
    "    \"\"\"\n",
    "    print(\"=\"*40 + \"Simulation results\" + \"=\"*40)\n",
    "\n",
    "    #iterate through each strategy and scale to print results for all\n",
    "    for params, res in results.items():\n",
    "        scale, strategy = params\n",
    "        total_time, metrics, total_distance = res\n",
    "        \n",
    "        # Unpack the new, extended metrics tuple\n",
    "        delay_inc, _, success, success_delay, stacked_count, rejected_count = metrics\n",
    "        \n",
    "        total_delivered = success + success_delay\n",
    "        if total_delivered == 0: continue\n",
    "        avg_delay = delay_inc / success_delay if success_delay > 0 else 0\n",
    "        \n",
    "        print(f\"Scenario: '{strategy}' @ {int(scale*100)}% Flotte ({int(total_active_couriers * scale)} Fahrer)\")\n",
    "        print(f\"Total Time to clear all orders: {total_time/3600:.2f} Stunden ({total_time/60:.0f} Minuten)\")\n",
    "        print(f\"On-time or Early Deliveries: {success}\")\n",
    "        print(f\"Late Deliveries: {success_delay}\")\n",
    "        print(f\"Avg. Delay (for late deliveries): {avg_delay/60:.1f} Minuten\")\n",
    "        print(f\"Total Distance Traveled (Hexagons): {total_distance} Zellen\")\n",
    "        print(f\"Total Stacked Assignments: {stacked_count}\")\n",
    "        print(f\"Total Rejected Offers: {rejected_count}\")\n",
    "        \n",
    "        print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7087d325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_monte_carlo_iteration(iteration_seed, all_constants, sim_data_df, total_couriers, strategies_list, scales_list, rejection_m):\n",
    "    '''\n",
    "    Runs a complete simulation for all scenarios\n",
    "    with a given seed and returns the results.\n",
    "    Args: - iteration_seed = random seed used for iteration\n",
    "          - all_constants = all constants needed for the simulation etc. pp\n",
    "          - sim_data_df = the predefined dataset with couriers etc.\n",
    "          - total_couriers = number of couriers for the run and scale\n",
    "          - strategies_list = to determine which strategy starts for the run (is iterated over)\n",
    "          - scales_list = we can use different scales for the monte-carlo\n",
    "          - rejection_m = the rejection model for courier assigments\n",
    "    '''\n",
    "    np.random.seed(iteration_seed) #a new seed for each iteration\n",
    "    iteration_results = {} #to memorize all results for df and plotting\n",
    "\n",
    "    repositioning_enabled_strategies = ['Repositioning', 'Combined_Split','Combined_SPAB'] #For repositioning warm-up\n",
    "\n",
    "    for scale in scales_list:\n",
    "        for strategy in strategies_list: #each run, we need to reset some values\n",
    "            timestart = all_constants['initial_timestart']\n",
    "            sim_data = sim_data_df.copy()\n",
    "            initial_order_ids = set(sim_data['order_id'])\n",
    "            num_initial_orders = len(initial_order_ids)\n",
    "            delivered_order_ids = set()\n",
    "            metrics = (0, 0, 0, 0, 0, 0)\n",
    "            order_queue = []\n",
    "            assignment_log = []\n",
    "            hindsight_cache = set()\n",
    "\n",
    "            couriers = abm.initiate_couriers(int(total_couriers * scale), sim_data_df) #initiate the couriers on the grid\n",
    "\n",
    "            # Warm-up Phase if repositioning is activated\n",
    "            if strategy in repositioning_enabled_strategies:\n",
    "                warmup_seconds = 15 * 60\n",
    "                warmup_start_time = timestart - warmup_seconds\n",
    "                \n",
    "                #run repositioning\n",
    "                for t in range(warmup_start_time, timestart, all_constants['steps']):\n",
    "                    couriers, _, delivered_order_ids = abm.move_couriers_new(couriers, t, (0, 0, 0, 0, 0, 0), delivered_order_ids, all_constants['SPEED_HEX_PER_STEP'], all_constants['steps'])\n",
    "                    first_bin_key = pd.to_datetime(timestart, unit='s').floor('15min')\n",
    "                    dynamic_demand = all_constants['pre_binned_demand'].get(first_bin_key, {})\n",
    "                    if dynamic_demand:\n",
    "                        repositioning.run_repositioning_strategy(\n",
    "                            couriers, dynamic_demand, t, [],\n",
    "                            all_constants['SPEED_HEX_PER_STEP'], all_constants['steps'],\n",
    "                            all_constants['MACRO_RESOLUTION'], all_constants['WORK_RESOLUTION']\n",
    "                        )\n",
    "            print(strategy +\" \" + \"begins\") #for logging\n",
    "\n",
    "            # Main Simulation Loop\n",
    "            while len(delivered_order_ids) < num_initial_orders:\n",
    "                couriers, sim_data, metrics, delivered_order_ids, order_queue, assignment_log, hindsight_cache = run_abm(\n",
    "                    timestart, all_constants['steps'], sim_data, couriers, metrics, delivered_order_ids, order_queue,\n",
    "                    strategy, all_constants, rejection_m, assignment_log, hindsight_cache\n",
    "                )\n",
    "                timestart += all_constants['steps']\n",
    "\n",
    "            # Save metrics for each iteration\n",
    "            total_simulation_time = timestart - all_constants['initial_timestart']\n",
    "            total_distance = abm.calculate_total_distance_in_hexes(couriers)\n",
    "            iteration_results[(scale, strategy)] = (total_simulation_time, metrics, total_distance)\n",
    "\n",
    "    return iteration_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d9cbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_monte_carlo_runs = 10 #10 need to be enough (Split are too many and at higher utilisation it is really slow)\n",
    "all_run_results = [] #save all results\n",
    "\n",
    "constants = {\n",
    "    'initial_timestart': 1666591200, #2022-10-24 @14:00\n",
    "    'SPEED_HEX_PER_STEP': 8, #count of hexgagon jump per step in workresolution\n",
    "    'simulation_duration_hours': 3, #we simulate 14:00-17:00 e.g.\n",
    "    'steps': 30, #duration of a single simulation timestep in seconds\n",
    "    'repositioning_interval': 15 * 60, #the interval in seconds at which the repositioning strategy is triggered\n",
    "    'MAX_ACCEPTABLE_DELAY_SECONDS': 5 * 60, #for assignments, to wait for better courier\n",
    "    'MAX_QUEUE_ATTEMPTS': 20, #If in queue for 10 minutes -> best free courier is chosen \n",
    "    'pre_binned_demand': pre_binned_demand, # Our prediction for the three hours\n",
    "    'MACRO_RESOLUTION': 8, #Hexagon resolution demand prediction and zones\n",
    "    'WORK_RESOLUTION': 13 # Actors position and movement \n",
    "}\n",
    "\n",
    "warmup_duration_seconds = 30 * 60  # 30 Minutes no metric tracking\n",
    "metrics_start_time = constants['initial_timestart'] + warmup_duration_seconds\n",
    "\n",
    "# Different phases to mark orders to be tracked and which are just for warmup\n",
    "sim_data_filtered['phase'] = np.where(\n",
    "    sim_data_filtered['platform_order_time'] < metrics_start_time, \n",
    "    'warmup', \n",
    "    'tracked'\n",
    ")\n",
    "\n",
    "# Use the bins defined in the second section \n",
    "jenks_bins = [-0.001, 0.164, 0.239, 0.302, 0.363, 0.421, 0.479, 0.54, 0.617, 0.741, 1.0]\n",
    "\n",
    "# bin labels for split\n",
    "bin_labels = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "# Added to df\n",
    "sim_data_filtered['distance_bin'] = pd.cut(sim_data_filtered['normalized_distance'],\n",
    "                                           bins=jenks_bins,\n",
    "                                           labels=bin_labels,\n",
    "                                           include_lowest=True)\n",
    "\n",
    "constants['SPLIT_BIN_THRESHOLD'] = 6 #determine which bin in this run\n",
    "strategies = ['Combined_SPAB', 'Repositioning']\n",
    "#strategies = ['Standard','Repositioning', 'Combined_Split','SPAB','Combined_SPAB'] #Strategies for run. For baseline take any name, as it is not triggering the strategies\n",
    "courier_scales = [1.0] # determine the fleet sizes\n",
    "total_active_couriers = sim_data_filtered['courier_id'].unique().shape[0] * 0.8 #determine the number of couriers\n",
    "\n",
    "print(f\"Begin with monte-carlo runs with {num_monte_carlo_runs} iteration(s)\")\n",
    "\n",
    "# See the progress\n",
    "for i in tqdm(range(num_monte_carlo_runs), desc=\"Monte-Carlo-Run(s)\"):\n",
    "    current_seed = i\n",
    "    single_run_data = run_monte_carlo_iteration(\n",
    "        iteration_seed=current_seed, all_constants=constants,\n",
    "        sim_data_df=sim_data_filtered, total_couriers=total_active_couriers,\n",
    "        strategies_list=strategies, scales_list=courier_scales, rejection_m=rejection_model\n",
    "    )\n",
    "\n",
    "    for params, res in single_run_data.items():\n",
    "        scale, strategy = params\n",
    "        total_time, metrics, total_distance = res\n",
    "        delay_inc, _, success, success_delay, stacked_count, rejected_count = metrics\n",
    "        all_run_results.append({\n",
    "            'run_id': i, 'scale': scale, 'strategy': strategy, 'on_time_deliveries': success,\n",
    "            'late_deliveries': success_delay, 'total_delivered': success + success_delay,\n",
    "            'avg_delay_late': (delay_inc / success_delay) / 60 if success_delay > 0 else 0,\n",
    "            'stacked_assignments': stacked_count, 'rejected_offers': rejected_count,\n",
    "            'total_distance_hex': total_distance\n",
    "        })\n",
    "\n",
    "print(\"All monte-carlo runs done!\")\n",
    "\n",
    "results_df = pd.DataFrame(all_run_results)\n",
    "#results_df.to_csv(\"monte_carlo_results.csv\", index=False) #save the results in a dataframe\n",
    "print(results_df.head())\n",
    "\n",
    "\n",
    "#Boxplot for all scale and strategy combinations\n",
    "plt.figure(figsize=(14, 8)) \n",
    "sns.boxplot(data=results_df, x='strategy', y='on_time_deliveries', hue='scale')\n",
    "plt.title(f'Distribution of on-time deliveries ({num_monte_carlo_runs} Monte-Carlo-Runs)')\n",
    "plt.xlabel('Strategy')\n",
    "plt.ylabel('Absolute number of on-time deliveries')\n",
    "plt.legend(title='Fleet size (scale)', bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
