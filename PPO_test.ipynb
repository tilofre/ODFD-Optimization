{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccf43bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import time\n",
    "import abm_utils.abm as abm\n",
    "import abm_utils.repositioning as repositioning\n",
    "import abm_utils.split as split\n",
    "from  ppo_utils.ppo_agent import PPOAgent, EnhancedStateHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedaaa5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-20 17:16:55,439 - DEBUG - Creating converter from 3 to 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPO-Modelle erfolgreich aus dem Verzeichnis 'Data/final_ppo_agent_140' geladen.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This is the same as the ABM.ipynb but its decisions are based on the PPO agent. Thus only the things differ to ABM.ipynb are described.\n",
    "\"\"\"\n",
    "\n",
    "STATE_DIM = 4  #The same state dimensions as during the training\n",
    "ACTION_DIM = 2 # Direct, Split\n",
    "\n",
    "# Initialise state handler\n",
    "state_handler = EnhancedStateHandler(grid=None) \n",
    "\n",
    "# Create PPO instance for decision making\n",
    "decision_agent_ppo = PPOAgent(state_dim=STATE_DIM, action_dim=ACTION_DIM)\n",
    "\n",
    "# Load weights of NNs\n",
    "decision_agent_ppo.load_models(\"Data/final_ppo_agent_140\") # Der Ordnername muss Ã¼bereinstimmen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f208d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the test data\n",
    "sim_data_filtered = pd.read_csv(\"Data/TestData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81aab7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-20 17:17:01,786 - DEBUG - Using json encoder/decoder\n"
     ]
    }
   ],
   "source": [
    "forecastData = pd.read_parquet(\"Data/predicted_values_2022-10-24_14-17.parquet\") #Predicted values for our timeframe between 14-17 with h3 indices\n",
    "\"\"\"\n",
    "First we need to create a dictionary with all predicted values in hexagons res = 8, which our abm can use for repositioning\n",
    "\n",
    "\"\"\"\n",
    "wide_df = forecastData.pivot(\n",
    "    index='time_bin',\n",
    "    columns='hex_id', \n",
    "    values='predicted_order_count'\n",
    ")\n",
    "\n",
    "wide_df.index = pd.to_datetime(wide_df.index)\n",
    "wide_df = wide_df.fillna(0)\n",
    "predictions_dict = wide_df.to_dict(orient='index')\n",
    "first_key = list(predictions_dict.keys())[0]\n",
    "\n",
    "pre_binned_demand = predictions_dict #pre_binned_demand is our 15 minutes bin per hexagon dictionary with which we will test our strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858d1a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_abm(timestart, steps, data, couriers, metrics, delivered_order_ids, order_queue, strategy, constants, rejection_model,assignment_log,decision_agent, state_handler):\n",
    "    \"\"\"\n",
    "    Our abm dispatcher which controls all simulation functions.\n",
    "    Args:   - constants will be defined in main simulation setup and is a tuple of numbers\n",
    "            - data is our dataframe for the three hours\n",
    "            - couriers are all couriers\n",
    "            - strategy is the strategy used\n",
    "            - metrics is a tuple of values to calculate simulation metrics (now with 6 values)\n",
    "            - rejection model is the imported logistic regression probabilistic model\n",
    "            - delivered_order_ids are the orders delivered so far and at what timestep\n",
    "            - order_queue is the set of orders, which are in the queue \n",
    "    \"\"\"\n",
    "    # Moving the couriers\n",
    "    couriers, metrics, delivered_order_ids = abm.move_couriers_new(\n",
    "        couriers, timestart, metrics, delivered_order_ids,\n",
    "        constants['SPEED_HEX_PER_STEP'], constants['steps']\n",
    "    )\n",
    "    if len(order_queue) > 50:\n",
    "        constants[\"MAX_ACCEPTABLE_DELAY_SECONDS\"] = 15 * 60\n",
    "    elif len(order_queue) > 20:\n",
    "        constants[\"MAX_ACCEPTABLE_DELAY_SECONDS\"]  = 10 * 60\n",
    "    else:\n",
    "        constants[\"MAX_ACCEPTABLE_DELAY_SECONDS\"]  = 5 * 60\n",
    "    # Different strategies need different functions\n",
    "    repositioning_enabled_strategies = ['Repositioning', 'Combined_Split']\n",
    "    splitting_enabled_strategies = ['Split', 'Combined_Split']\n",
    "    if strategy in repositioning_enabled_strategies and (timestart - constants['initial_timestart']) % constants['repositioning_interval'] == 0:\n",
    "        current_bin_key = pd.to_datetime(timestart, unit='s').floor('15min') + pd.Timedelta(hours=8)\n",
    "        dynamic_demand = constants['pre_binned_demand'].get(current_bin_key, {})\n",
    "        if dynamic_demand:\n",
    "            repositioning.run_repositioning_strategy(\n",
    "                couriers, dynamic_demand, timestart, order_queue,\n",
    "                constants['SPEED_HEX_PER_STEP'], constants['steps'],\n",
    "                constants['MACRO_RESOLUTION'], constants['WORK_RESOLUTION']\n",
    "            )\n",
    "\n",
    "    # prepare the orders for the step\n",
    "    new_orders_this_step = [order for _, order in data[\n",
    "        (data['platform_order_time'] >= timestart) & \n",
    "        (data['platform_order_time'] < timestart + steps)\n",
    "    ].iterrows()]\n",
    "    for order in new_orders_this_step:\n",
    "        order['assignment_status'] = 'pending_full'\n",
    "\n",
    "    all_pending_orders = order_queue + [(order, 0) for order in new_orders_this_step]\n",
    "    next_order_queue = []\n",
    "    processed_order_ids_this_step = set()\n",
    "\n",
    "    # process all orders\n",
    "    for order, attempts in all_pending_orders:\n",
    "        if order['order_id'] in processed_order_ids_this_step:\n",
    "            continue\n",
    "\n",
    "        was_processed = False\n",
    "        if attempts > constants['MAX_QUEUE_ATTEMPTS']:\n",
    "            was_processed, metrics, assignment_log = abm.handle_standard_assignment(order, attempts, couriers, timestart, constants, rejection_model, processed_order_ids_this_step, metrics, assignment_log)\n",
    "    \n",
    "        elif strategy in splitting_enabled_strategies:\n",
    "            order_distance_feature = state_handler.get_order_specific_feature(order) #get distance feature\n",
    "            global_features = state_handler.get_global_state_features(couriers, all_pending_orders) #get information about couriers and utilisation\n",
    "            state_features = np.concatenate(([order_distance_feature], global_features)) #merge features\n",
    "            action, _, _ = decision_agent.get_action(state_features, deterministic=True) #decide for action\n",
    "\n",
    "            #if agent says direct, then standard assignment\n",
    "            if action == 0 or order['assignment_status'] == 'pending_part2':\n",
    "                was_processed, metrics, assignment_log = abm.handle_standard_assignment(order, attempts, couriers, timestart, constants, rejection_model, processed_order_ids_this_step, metrics, assignment_log)\n",
    "            else:\n",
    "                # The agent decided for option split\n",
    "                idle_couriers = [c for c in couriers if c.state == 'IDLE' and order['order_id'] not in c.rejected_orders]\n",
    "                c1, c2, r1, r2 = split.process_split_delivery(order, idle_couriers, timestart, constants)\n",
    "                \n",
    "                if c1 and c2:\n",
    "                    was_processed, metrics = split.execute_split_assignment(\n",
    "                        order, c1, c2, r1, r2, timestart, constants, \n",
    "                        rejection_model, processed_order_ids_this_step, next_order_queue, metrics\n",
    "                    )\n",
    "        else: \n",
    "            was_processed, metrics, assignment_log = abm.handle_standard_assignment(order, attempts, couriers, timestart, constants, rejection_model, processed_order_ids_this_step, metrics, assignment_log)\n",
    "\n",
    "        if not was_processed: \n",
    "            next_order_queue.append((order, attempts + 1))\n",
    "\n",
    "    return couriers, data, metrics, delivered_order_ids, next_order_queue, assignment_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed571f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_effectiveness(results, total_active_couriers):\n",
    "    \"\"\"\n",
    "    Prints a summary of simulation results\n",
    "    Arg. results: A dictionary containing the simulation outcomes. Format: {(scale, strategy): (total_time, metrics, total_distance)}\n",
    "    \"\"\"\n",
    "    print(\"=\"*40 + \"Simulation results\" + \"=\"*40)\n",
    "\n",
    "    #iterate through each strategy and scale to print results for all\n",
    "    for params, res in results.items():\n",
    "        scale, strategy = params\n",
    "        total_time, metrics, total_distance = res\n",
    "        \n",
    "        # Unpack the new, extended metrics tuple\n",
    "        delay_inc, _, success, success_delay, stacked_count, rejected_count = metrics\n",
    "        \n",
    "        total_delivered = success + success_delay\n",
    "        if total_delivered == 0: continue\n",
    "        avg_delay = delay_inc / success_delay if success_delay > 0 else 0\n",
    "        \n",
    "        print(f\"Scenario: '{strategy}' @ {int(scale*100)}% Flotte ({int(total_active_couriers * scale)} Fahrer)\")\n",
    "        print(f\"Total Time to clear all orders: {total_time/3600:.2f} Stunden ({total_time/60:.0f} Minuten)\")\n",
    "        print(f\"On-time or Early Deliveries: {success}\")\n",
    "        print(f\"Late Deliveries: {success_delay}\")\n",
    "        print(f\"Avg. Delay (for late deliveries): {avg_delay/60:.1f} Minuten\")\n",
    "        print(f\"Total Distance Traveled (Hexagons): {total_distance} Zellen\")\n",
    "        print(f\"Total Stacked Assignments: {stacked_count}\")\n",
    "        print(f\"Total Rejected Offers: {rejected_count}\")\n",
    "        \n",
    "        print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cde44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation initialisiert. Metriken werden fÃ¼r 5240 'tracked' AuftrÃ¤ge gesammelt (nach t=30min).\n",
      "Starting Simulation:'Split' with 1006 couriers (80%)...\n",
      "  [SPLIT SUCCESS] Order 22321 planned and assigned to C873 and C952\n",
      "  [SPLIT SUCCESS] Order 38241 planned and assigned to C936 and C169\n",
      "  [SPLIT SUCCESS] Order 82686 planned and assigned to C16 and C176\n",
      "  [SPLIT SUCCESS] Order 101324 planned and assigned to C345 and C545\n",
      "  [SPLIT SUCCESS] Order 170916 planned and assigned to C37 and C8\n",
      "  [SPLIT SUCCESS] Order 261811 planned and assigned to C540 and C105\n",
      "  [SPLIT SUCCESS] Order 292985 planned and assigned to C272 and C224\n",
      "  [SPLIT SUCCESS] Order 365355 planned and assigned to C189 and C88\n",
      "  [SPLIT SUCCESS] Order 406099 planned and assigned to C877 and C671\n",
      "  [SPLIT SUCCESS] Order 416731 planned and assigned to C11 and C402\n",
      "  [SPLIT SUCCESS] Order 422019 planned and assigned to C825 and C34\n",
      "  [SPLIT SUCCESS] Order 482854 planned and assigned to C290 and C992\n",
      "  [SPLIT SUCCESS] Order 540216 planned and assigned to C892 and C280\n",
      "  [SPLIT SUCCESS] Order 51186 planned and assigned to C619 and C955\n",
      "  [SPLIT SUCCESS] Order 82687 planned and assigned to C534 and C38\n",
      "  [SPLIT SUCCESS] Order 149701 planned and assigned to C29 and C889\n",
      "  [SPLIT SUCCESS] Order 281779 planned and assigned to C42 and C1001\n",
      "  [SPLIT SUCCESS] Order 356975 planned and assigned to C587 and C0\n",
      "  [SPLIT SUCCESS] Order 419446 planned and assigned to C999 and C633\n",
      "  [SPLIT SUCCESS] Order 432664 planned and assigned to C500 and C182\n",
      "  [SPLIT SUCCESS] Order 461877 planned and assigned to C331 and C832\n",
      "  [SPLIT SUCCESS] Order 475090 planned and assigned to C49 and C456\n",
      "  [SPLIT SUCCESS] Order 482855 planned and assigned to C413 and C261\n",
      "  [SPLIT SUCCESS] Order 535019 planned and assigned to C577 and C372\n",
      "  [SPLIT SUCCESS] Order 568404 planned and assigned to C1 and C279\n",
      "  [SPLIT SUCCESS] Order 63704 planned and assigned to C47 and C518\n",
      "  [SPLIT SUCCESS] Order 152795 planned and assigned to C838 and C389\n",
      "  [SPLIT SUCCESS] Order 194629 planned and assigned to C650 and C576\n",
      "  [SPLIT SUCCESS] Order 218375 planned and assigned to C366 and C711\n",
      "  [SPLIT SUCCESS] Order 238663 planned and assigned to C32 and C57\n",
      "  [SPLIT SUCCESS] Order 276001 planned and assigned to C375 and C531\n",
      "  [SPLIT SUCCESS] Order 345869 planned and assigned to C749 and C28\n",
      "  [SPLIT SUCCESS] Order 376321 planned and assigned to C10 and C661\n",
      "  [SPLIT SUCCESS] Order 424752 planned and assigned to C691 and C404\n",
      "  [SPLIT SUCCESS] Order 448783 planned and assigned to C93 and C316\n",
      "  [SPLIT SUCCESS] Order 477690 planned and assigned to C152 and C591\n",
      "  [SPLIT SUCCESS] Order 521852 planned and assigned to C840 and C421\n",
      "  [SPLIT SUCCESS] Order 395190 planned and assigned to C1000 and C101\n",
      "  [SPLIT SUCCESS] Order 438060 planned and assigned to C690 and C970\n",
      "  [SPLIT SUCCESS] Order 558207 planned and assigned to C283 and C307\n",
      "  [SPLIT SUCCESS] Order 85717 planned and assigned to C662 and C679\n",
      "  [SPLIT SUCCESS] Order 28671 planned and assigned to C559 and C600\n",
      "  [SPLIT SUCCESS] Order 70013 planned and assigned to C449 and C607\n",
      "  [SPLIT SUCCESS] Order 79526 planned and assigned to C850 and C262\n",
      "  [SPLIT SUCCESS] Order 110341 planned and assigned to C651 and C350\n",
      "  [SPLIT SUCCESS] Order 337455 planned and assigned to C318 and C115\n",
      "  [SPLIT SUCCESS] Order 365356 planned and assigned to C916 and C813\n",
      "  [SPLIT SUCCESS] Order 414088 planned and assigned to C913 and C416\n",
      "  [SPLIT SUCCESS] Order 521854 planned and assigned to C275 and C574\n",
      "  [SPLIT SUCCESS] Order 31850 planned and assigned to C628 and C684\n",
      "  [SPLIT SUCCESS] Order 85718 planned and assigned to C113 and C918\n",
      "  [SPLIT SUCCESS] Order 122384 planned and assigned to C391 and C368\n",
      "  [SPLIT SUCCESS] Order 200524 planned and assigned to C344 and C751\n",
      "  [SPLIT SUCCESS] Order 323757 planned and assigned to C492 and C258\n",
      "  [SPLIT SUCCESS] Order 427325 planned and assigned to C890 and C124\n",
      "  [SPLIT SUCCESS] Order 537671 planned and assigned to C334 and C779\n",
      "  [SPLIT SUCCESS] Order 555610 planned and assigned to C871 and C722\n",
      "  [SPLIT SUCCESS] Order 131573 planned and assigned to C12 and C797\n",
      "  [SPLIT SUCCESS] Order 194630 planned and assigned to C193 and C524\n",
      "  [SPLIT SUCCESS] Order 238668 planned and assigned to C580 and C150\n",
      "  [SPLIT SUCCESS] Order 238670 planned and assigned to C639 and C585\n",
      "  [SPLIT SUCCESS] Order 411415 planned and assigned to C61 and C104\n",
      "  [SPLIT SUCCESS] Order 430004 planned and assigned to C237 and C17\n",
      "  [SPLIT SUCCESS] Order 448784 planned and assigned to C256 and C142\n",
      "  [SPLIT SUCCESS] Order 469808 planned and assigned to C958 and C766\n",
      "  [SPLIT SUCCESS] Order 519183 planned and assigned to C244 and C735\n",
      "  [SPLIT SUCCESS] Order 57457 planned and assigned to C784 and C206\n",
      "  [SPLIT SUCCESS] Order 176900 planned and assigned to C957 and C56\n",
      "  [SPLIT SUCCESS] Order 238665 planned and assigned to C274 and C719\n",
      "  [SPLIT SUCCESS] Order 419447 planned and assigned to C928 and C926\n",
      "  [SPLIT SUCCESS] Order 456608 planned and assigned to C317 and C36\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_30500\\4072536077.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;31m# Main Simulation Loop Begins here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelivered_order_ids\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mnum_initial_orders\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[1;31m# Function call of abm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m             couriers, sim_data, metrics, delivered_order_ids, order_queue, assignment_log = run_abm(\n\u001b[0m\u001b[0;32m     92\u001b[0m                 \u001b[0mtimestart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconstants\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'steps'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0msim_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcouriers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelivered_order_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder_queue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m                 \u001b[0mstrategy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconstants\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrejection_model\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0massignment_log\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecision_agent_ppo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_handler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m             )\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_30500\\1623806890.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(timestart, steps, data, couriers, metrics, delivered_order_ids, order_queue, strategy, constants, rejection_model, assignment_log, decision_agent, state_handler)\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mstrategy\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msplitting_enabled_strategies\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[0morder_distance_feature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_order_specific_feature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mglobal_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_global_state_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcouriers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_pending_orders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mstate_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0morder_distance_feature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m             \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecision_agent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m             \u001b[1;31m# ÃberprÃ¼fen Sie den Distanz-Bin direkt aus dem 'order'-Objekt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[1;31m# AuftrÃ¤ge, deren Bin-Nummer KLEINER als der Schwellenwert ist, werden standardmÃ¤Ãig behandelt.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0maction\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'assignment_status'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'pending_part2'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\freud\\OneDrive - UniversitÃ¤t MÃ¼nster\\Master Thesis\\Python Code Thesis\\ppo_utils\\ppo_agent.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, state, deterministic)\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0mstate_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m         \u001b[0maction_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[1;31m# WÃ¤hle die Aktion mit der hÃ¶chsten Wahrscheinlichkeit (fÃ¼r Inferenz)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\freud\\anaconda3\\envs\\tf310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\freud\\anaconda3\\envs\\tf310\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m                 \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mcopied_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m             \u001b[0mlayout_map_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_map_subclass_model_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_layout_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\freud\\anaconda3\\envs\\tf310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\freud\\anaconda3\\envs\\tf310\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1093\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1094\u001b[0m                 with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1095\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 ):\n\u001b[1;32m-> 1097\u001b[1;33m                     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1098\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\freud\\anaconda3\\envs\\tf310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m                 \u001b[0mnew_e\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mnew_e\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m             \u001b[1;32mdel\u001b[0m \u001b[0mbound_signature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\freud\\anaconda3\\envs\\tf310\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    506\u001b[0m         \u001b[0mReturns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0msingle\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m             \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m         \"\"\"\n\u001b[1;32m--> 510\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_internal_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\freud\\anaconda3\\envs\\tf310\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    663\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_id\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtensor_dict\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflat_input_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    664\u001b[0m                     \u001b[1;32mcontinue\u001b[0m  \u001b[1;31m# Node is not computable, try skipping.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 667\u001b[1;33m                 \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m                 \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m                 for x_id, y in zip(\n",
      "\u001b[1;32mc:\\Users\\freud\\anaconda3\\envs\\tf310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\freud\\anaconda3\\envs\\tf310\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1093\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1094\u001b[0m                 with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1095\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 ):\n\u001b[1;32m-> 1097\u001b[1;33m                     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1098\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\freud\\anaconda3\\envs\\tf310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m                 \u001b[0mnew_e\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mnew_e\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m             \u001b[1;32mdel\u001b[0m \u001b[0mbound_signature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\freud\\anaconda3\\envs\\tf310\\lib\\site-packages\\keras\\layers\\core\\dense.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    237\u001b[0m                 outputs = tf.nn.embedding_lookup_sparse(\n\u001b[0;32m    238\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcombiner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"sum\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m                 )\n\u001b[0;32m    240\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m                 \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m         \u001b[1;31m# Broadcast kernel to inputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrank\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\freud\\anaconda3\\envs\\tf310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\freud\\anaconda3\\envs\\tf310\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1174\u001b[0m       \u001b[1;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1177\u001b[1;33m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1178\u001b[0m         \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m         \u001b[1;31m# TypeError, when given unexpected types.  So we need to catch both.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\freud\\anaconda3\\envs\\tf310\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, output_type, name)\u001b[0m\n\u001b[0;32m   3710\u001b[0m         \u001b[0madjoint_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madjoint_b\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3711\u001b[0m         return gen_math_ops.batch_mat_mul_v3(\n\u001b[0;32m   3712\u001b[0m             a, b, adj_x=adjoint_a, adj_y=adjoint_b, Tout=output_type, name=name)\n\u001b[0;32m   3713\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3714\u001b[1;33m         return gen_math_ops.mat_mul(\n\u001b[0m\u001b[0;32m   3715\u001b[0m             a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n",
      "\u001b[1;32mc:\\Users\\freud\\anaconda3\\envs\\tf310\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   6014\u001b[0m         transpose_b)\n\u001b[0;32m   6015\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6016\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6017\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6018\u001b[1;33m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6019\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6020\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6021\u001b[0m       return mat_mul_eager_fallback(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The main code is the same as in the standard notebook\n",
    "\"\"\"\n",
    "\n",
    "constants = {\n",
    "    'initial_timestart': 1666591200, #2022-10-24 @14:00\n",
    "    'SPEED_HEX_PER_STEP': 8, #count of hexgagon jump per step in workresolution\n",
    "    'simulation_duration_hours': 3, #we simulate 14:00-17:00 e.g.\n",
    "    'steps': 30, #duration of a single simulation timestep in seconds\n",
    "    'repositioning_interval': 15 * 60, #the interval in seconds at which the repositioning strategy is triggered\n",
    "    'MAX_ACCEPTABLE_DELAY_SECONDS': 5 * 60, #for assignments, to wait for better courier\n",
    "    'MAX_QUEUE_ATTEMPTS': 20, #If in queue for 10 minutes -> best free courier is chosen \n",
    "    'pre_binned_demand': pre_binned_demand, # Our prediction for the three hours\n",
    "    'MACRO_RESOLUTION': 8, #Hexagon resolution demand prediction and zones\n",
    "    'WORK_RESOLUTION': 13 # Actors position and movement \n",
    "}\n",
    "final_courier_states = {} #for evaluation\n",
    "results = {} #for evaluation\n",
    "\n",
    "rejection_model = joblib.load('Data/rejection_model.joblib')\n",
    "\n",
    "warmup_duration_seconds = 30 * 60  # 30 Minuten\n",
    "\n",
    "# Berechnen Sie den Startzeitpunkt fÃ¼r die Metrikerfassung\n",
    "metrics_start_time = constants['initial_timestart'] + warmup_duration_seconds\n",
    "\n",
    "# FÃ¼gen Sie eine neue Spalte 'phase' hinzu, die die AuftrÃ¤ge kategorisiert\n",
    "sim_data_filtered['phase'] = np.where(\n",
    "    sim_data_filtered['platform_order_time'] < metrics_start_time, \n",
    "    'warmup', \n",
    "    'tracked'\n",
    ")\n",
    "\n",
    "# Informieren Sie den Benutzer Ã¼ber die Aufteilung\n",
    "tracked_orders_count = (sim_data_filtered['phase'] == 'tracked').sum()\n",
    "print(f\"Simulation initialisiert. Metriken werden fÃ¼r {tracked_orders_count} 'tracked' AuftrÃ¤ge gesammelt (nach t=30min).\")\n",
    "\n",
    "\n",
    "#determine the total number of couriers who were active in time window\n",
    "total_active_couriers = sim_data_filtered['courier_id'].unique().shape[0] \n",
    "total_active_couriers = total_active_couriers*0.8\n",
    "\n",
    "#define the scenarios to run\n",
    "strategies = ['Split', 'Combined_Split']\n",
    "repositioning_enabled_strategies = ['Repositioning', 'Combined_Split']\n",
    "courier_scales = [0.8]\n",
    "assignment_log_dict = {}\n",
    "\n",
    "#Loop through each fleet scale\n",
    "for scale in courier_scales:\n",
    "    for strategy in strategies: #loop through each strategy\n",
    "        \n",
    "        #reset the simulation states\n",
    "        start_time_real = time.time()\n",
    "        timestart = constants['initial_timestart'] \n",
    "        sim_data = sim_data_filtered.copy()\n",
    "        initial_order_ids = set(sim_data['order_id'])\n",
    "        num_initial_orders = len(initial_order_ids)\n",
    "        delivered_order_ids = set()\n",
    "        # metrics = (delay_inc, 0, success, success_delay, stacked_orders, rejected_orders)\n",
    "        metrics = (0, 0, 0, 0, 0, 0)\n",
    "        order_queue = []\n",
    "        assignment_log = []\n",
    "        \n",
    "        #initiate couriers at their position based on scale\n",
    "        couriers = abm.initiate_couriers(int(total_active_couriers * scale), sim_data_filtered)      \n",
    "       \n",
    "        \n",
    "        print(f\"Starting Simulation:'{strategy}' with {len(couriers)} couriers ({int(scale*100)}%)...\")\n",
    "\n",
    "        if strategy in repositioning_enabled_strategies:\n",
    "            #As we think that the fleet would not start at point zero\n",
    "            print(f\"Running warm up phase for fleet deployment\")\n",
    "            warmup_seconds = 15 * 60 \n",
    "            warmup_start_time = constants['initial_timestart']  - warmup_seconds\n",
    "            \n",
    "            for t in range(warmup_start_time, constants['initial_timestart'] , constants['steps'] ):\n",
    "                # Move couriers in repositioning task\n",
    "                couriers, _, delivered_order_ids = abm.move_couriers_new(couriers, t, (0, 0, 0, 0, 0, 0), delivered_order_ids, constants['SPEED_HEX_PER_STEP'], constants['steps'])\n",
    "\n",
    "                 # Use the pre-binned forecast for the first time-slot as the warm-up target.\n",
    "                first_bin_key = pd.to_datetime(constants['initial_timestart'] , unit='s').floor('15min') + pd.Timedelta(hours=8)\n",
    "                dynamic_demand = pre_binned_demand.get(first_bin_key, {})\n",
    "\n",
    "                # assign reposition tasks\n",
    "                if dynamic_demand:\n",
    "                    repositioning.run_repositioning_strategy(couriers, dynamic_demand, t, [], \n",
    "                        constants['SPEED_HEX_PER_STEP'], constants['steps'], \n",
    "                        constants['MACRO_RESOLUTION'], constants['WORK_RESOLUTION']\n",
    "                    )\n",
    "\n",
    "        # Main Simulation Loop Begins here\n",
    "        while len(delivered_order_ids) < num_initial_orders:\n",
    "            # Function call of abm\n",
    "            couriers, sim_data, metrics, delivered_order_ids, order_queue, assignment_log = run_abm(\n",
    "                timestart, constants['steps'] , sim_data, couriers, metrics, delivered_order_ids, order_queue,\n",
    "                strategy, constants, rejection_model , assignment_log, decision_agent_ppo, state_handler\n",
    "            )\n",
    "            timestart += constants['steps']  #add steps\n",
    "\n",
    "            #Log every 10 minutes\n",
    "            if (timestart - constants['initial_timestart'] ) % 600 == 0 and timestart > constants['initial_timestart'] :\n",
    "                print(f\"  > Time: {(timestart - constants['initial_timestart'] )/60:.0f} min | Delivered: {len(delivered_order_ids)}/{num_initial_orders} | Queue: {len(order_queue)}\")\n",
    "            \n",
    "        # store metrics\n",
    "        total_simulation_time = timestart - constants['initial_timestart'] \n",
    "        end_time_real = time.time()\n",
    "        assignment_log_dict[(scale, strategy)] = assignment_log\n",
    "        \n",
    "        final_courier_states[(scale, strategy)] = couriers\n",
    "\n",
    "        total_distance = abm.calculate_total_distance_in_hexes(couriers)        \n",
    "        results[(scale, strategy)] = (total_simulation_time, metrics, total_distance)\n",
    "        total_distance = abm.calculate_total_distance_in_hexes(couriers)\n",
    "\n",
    "        \n",
    "        print(f\"Simulation (Skala {int(scale*100)}%) finished in {end_time_real - start_time_real:.2f} real seconds.\")\n",
    "        print(f\"All {num_initial_orders} orders delivered. Total simulation time: {total_simulation_time/60:.0f} minutes.\")\n",
    "\n",
    "#final evaluation\n",
    "evaluate_effectiveness(results, total_active_couriers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
